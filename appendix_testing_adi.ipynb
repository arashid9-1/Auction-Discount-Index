{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math as m\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import training set, testset and estimated house price indices for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_table(r'C:\\Users\\ali\\Documents\\AVM_folder\\train_data.txt')\n",
    "testset = pd.read_table(r'C:\\Users\\ali\\Documents\\AVM_folder\\test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_index = pd.read_table(r'C:\\Users\\ali\\Documents\\AVM_folder\\postcode_districts_130923.csv', sep = \",\")\n",
    "ar_betas_m = pd.read_table(r'C:\\Users\\ali\\Documents\\AVM_folder\\ss_ar_dist_betas0410_interp.csv', sep = \",\")\n",
    "ar_params = pd.read_table(r'C:\\Users\\ali\\Documents\\AVM_folder\\ss_ar_dist_params0410.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the above csv files into pandas dataframes or dictionary objects to easily find information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_dates = [[year+'-'+month for month in np.array(range(1,13)).astype(str)]for year in np.array(range(1995,2024)).astype(str)]\n",
    "uniq_dates = np.array(uniq_dates).flatten()\n",
    "interp_index.columns = map(str.upper, interp_index.columns)\n",
    "interp_index['DATEID01'] = uniq_dates\n",
    "interp_index = interp_index.rename(columns={'DATEID01' : 'Index'})\n",
    "interp_index = interp_index.set_index('Index')\n",
    "interp_index_dict = {dist: interp_index[dist].to_dict() for dist in interp_index.columns}\n",
    "\n",
    "ar_betas_m.columns = map(str.upper, ar_betas_m.columns)\n",
    "ar_betas_m['DATEID01'] = uniq_dates\n",
    "ar_betas_m = ar_betas_m.rename(columns={'DATEID01' : 'Index'})\n",
    "ar_betas_m = ar_betas_m.set_index('Index')\n",
    "ar_params = ar_params.set_index('Unnamed: 0')\n",
    "ar_betas_dict_m = {dist: ar_betas_m[dist].to_dict() for dist in ar_betas_m.columns}\n",
    "ar_params_dict = {dist: ar_params[dist].to_dict() for dist in ar_params.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting columns to the minimum memeory time required to save memory \n",
    "# setting index to unique property identifiers allows AVMs to find all property\n",
    "# sales for a specific property quicky \n",
    "lrdata = trainset.copy()\n",
    "lrdata = lrdata.dropna(subset = ['Postcode'])\n",
    "lrdata = lrdata.dropna(subset = ['PAON'])\n",
    "lrdata['PAON'] = lrdata['PAON'].astype(str)\n",
    "lrdata['Postcode'] = lrdata['Postcode'].astype(str)\n",
    "lrdata['SAON'] = lrdata['SAON'].astype(str)\n",
    "lrdata['Price'] = lrdata['Price'].astype('int32')\n",
    "lrdata['Year'] = lrdata['Year'].astype('int16')\n",
    "lrdata['Month'] = lrdata['Month'].astype('int8')\n",
    "lrdata['dateYM'] = pd.to_datetime(lrdata['Year-Month'] + '-1', format='%Y-%m-%d')\n",
    "lrdata.set_index(['PAON', 'SAON', 'Postcode'], inplace=True)\n",
    "lrdata = lrdata.sort_index()\n",
    "lrdata['dateYM'] = pd.to_datetime(lrdata['Year-Month'] + '-' '1', format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = testset.drop(testset.iloc[:, 4:13],axis = 1)\n",
    "testset = testset.dropna(subset = ['Postcode'])\n",
    "testset = testset.dropna(subset = ['PAON'])\n",
    "testset['PAON'] = testset['PAON'].astype(str)\n",
    "testset['Postcode'] = testset['Postcode'].astype(str)\n",
    "testset['SAON'] = testset['SAON'].astype(str)\n",
    "testset['Price'] = testset['Price'].astype('int32')\n",
    "testset['Year'] = testset['Year'].astype('int16')\n",
    "testset['Month'] = testset['Month'].astype('int8')\n",
    "testset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVM values any address included in the land registry data at any specifed date using the estimater parameters using index inflation/deflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AVM_UP(number, postcode, when, name = None):\n",
    "    when_y = int(when[:4])\n",
    "    when_m = int(when[5:])    \n",
    "    t =  pd.to_datetime(when +'-' + '1', format='%Y-%m-%d')\n",
    "\n",
    "    if name == None:\n",
    "        name = 'nan'\n",
    "    \n",
    "    # Find all sales pertaining to the address using property number, postcode and name if provided\n",
    "\n",
    "    try:\n",
    "        sales = lrdata.loc[(number, name, postcode)]\n",
    "        if sales.empty: \n",
    "            return \"NO LRDATA\"\n",
    "    except KeyError:\n",
    "        return \"NO LRDATA\"\n",
    "\n",
    "    sales = sales.copy()\n",
    "    sales['distance'] = ((t.year - sales['dateYM'].dt.year) * 12  + t.month - sales['dateYM'].dt.month)\n",
    "    sales['distance'] = np.abs(sales['distance'])\n",
    "\n",
    "    \n",
    "    if sales.empty:\n",
    "        return \"NO LRDATA\"\n",
    "    \n",
    "    # Extract closest sale for the property for the specified date \n",
    "    sales = sales.loc[sales['distance'] == sales['distance'].min()]\n",
    "    \n",
    "    # Obtain time indices relevent to the sale \n",
    "    dist, y_m, price = sales['PC District'].iat[0], sales['Year-Month'].iat[0], int(sales['Price'].iat[0])\n",
    "\n",
    "    p_i_when = interp_index_dict[dist][when]\n",
    "    p_i_sale = interp_index_dict[dist][y_m]\n",
    "\n",
    "    # Inflate/deflate previous sale price to date specified \n",
    "    return price * (p_i_when / p_i_sale)\n",
    "\n",
    "AVM_UP('22','TS7 0LN', '2002-3') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AVM_ar_ym(number, postcode, when, name = None):\n",
    "    when_y = int(when[:4])\n",
    "    when_m = int(when[5:])\n",
    "    t =  pd.to_datetime(when + \"-1\", format='%Y-%m-%d')\n",
    "\n",
    "    if name == None:\n",
    "        name = 'nan'\n",
    "\n",
    "    try:\n",
    "        sales = lrdata.loc[(number, name, postcode)]\n",
    "        if sales.empty: \n",
    "            return \"NO LRDATA\"\n",
    "    except KeyError:\n",
    "        return \"NO LRDATA\"\n",
    "    \n",
    "    \n",
    "    sales = sales.copy()\n",
    "    sales['distance'] = ((t.year - sales['dateYM'].dt.year) * 12  + t.month - sales['dateYM'].dt.month)\n",
    "    sales['distance'] = np.abs(sales['distance'])\n",
    "\n",
    "    # This code is only included for the ADI construction since land registry started to include auction sales \n",
    "    # into the dataset \n",
    "    sales = sales[sales['distance'] >= 6]\n",
    "    \n",
    "    if sales.empty:\n",
    "        return \"NO LRDATA\"\n",
    "\n",
    "    sales = sales.loc[sales['distance'] == sales['distance'].min()]\n",
    "    \n",
    "    dist, t_1, price, gamma = sales['PC District'].iat[0], sales['Year-Month'].iat[0], np.log(int(sales['Price'].iat[0])), sales['distance'].iat[0] / 12\n",
    "\n",
    "    if t_1 == when:\n",
    "        return np.exp(price)\n",
    "    \n",
    "    # Inflate price using ARME model specification \n",
    "\n",
    "    phi, mu, mrs = ar_params_dict[dist]['phi'], ar_params_dict[dist]['mu'], ar_params_dict[dist]['mrs']\n",
    "\n",
    "    beta_t = ar_betas_dict_m[dist][when]\n",
    "    beta_t_1 = ar_betas_dict_m[dist][t_1]\n",
    "\n",
    "    y_j = mu + beta_t + (phi**gamma) * (price - mu - beta_t_1)\n",
    "\n",
    "    estimate = np.exp(y_j)\n",
    "\n",
    "    return estimate\n",
    "\n",
    "AVM_ar_ym('22','TS7 0LN', '2023-1') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_test1 = ar_test1.dropna(subset = ['Estimate'])\n",
    "ar_test1 = ar_test1.loc[ar_test1['Estimate']!='NO LRDATA']\n",
    "ar_test1 = ar_test1.loc[ar_test1['Estimate']!=0]\n",
    "ar_test1['E'] = ar_test1['Estimate'].astype(float)-ar_test1['Price'].astype(float)\n",
    "ar_test1['AE'] = abs(ar_test1['E'])\n",
    "ar_test1['SE'] = (ar_test1['E'])**2\n",
    "ar_test1['PE'] = ar_test1['E']/ar_test1['Price']\n",
    "ar_test1['PAE'] = abs(ar_test1['PE'])\n",
    "ar_test1['PSE'] = (ar_test1['PE'])**2\n",
    "ar_test2 = ar_test1.copy()\n",
    "ar_test2.sort_values(by=['PAE'],ascending=False, inplace = True, ignore_index = True)\n",
    "ar_test2 = ar_test2.tail(-len(ar_test2)//20)\n",
    "\n",
    "ar_yr_ds = {'ME': statistics.mean(ar_test2['E']), 'MAE': statistics.mean(ar_test2['AE']), 'RMSE': m.sqrt(statistics.mean(ar_test2['SE'])), 'MPE': statistics.mean(ar_test2['PE']), 'MAPE': statistics.mean(ar_test2['PAE']), 'RMSPE': m.sqrt(statistics.mean(ar_test2['PSE']))}\n",
    "ar_yr_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for constructing the ADI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig =  pd.read_table(r'C:\\Users\\ali\\Documents\\AVM_folder\\EIG_data.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep relevent rows\n",
    "eigdf = eig.drop(eig.columns[[0,1,4,5,10,11,12,14,15,16,17,18,19,41,42]], axis=1)\n",
    "eigdf.columns[18:24]\n",
    "eigdf = eigdf.loc[(eigdf.iloc[:, 13] == 1) & (eigdf.iloc[:, 18:24] == 0).all(axis=1)]\n",
    "eigdf = eigdf.loc[eigdf['LastBid']>0]\n",
    "eigdf['Number'] = eigdf['FullAddress'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the house number and postcode from eig dataset for auction sale. Then feed details into AVM for each row \n",
    "# To eastimate the price of the property on the conventional market \n",
    "df2 = eigdf\n",
    "df2 = df2.copy()\n",
    "df2['Estimate'] = df2.apply(lambda row: AVM_ar_ym(row.iloc[28], row.iloc[4], row.iloc[8]), axis=1 )\n",
    "df2 = df2.loc[df2['Estimate']!='NO LRDATA']\n",
    "df2 = df2.dropna(subset = ['Estimate'])\n",
    "df2['D/P'] = df2['LastBid'].astype(float)/df2['Estimate'].astype(float)\n",
    "\n",
    "df2.to_csv(r'C:\\Users\\ali\\Documents\\AVM_folder\\auction_estimated_ar.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['AuctionDate'] = pd.to_datetime(df2['AuctionDate'])\n",
    "df2['AuctionDate'] = df2['AuctionDate'].dt.to_period('M')\n",
    "# This is the ADI\n",
    "median_group = df2.groupby('AuctionDate')['D/P'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Figure 7\n",
    "moving_average = median_group.rolling(window=5).mean()\n",
    "sns.set_theme(context='paper', style='white', palette='deep', font='DejaVu Serif', font_scale=1)\n",
    "plt.figure(dpi=150)\n",
    "\n",
    "median_group.plot(style='o', color='blue', label='Monthly Median Auction Discount', markersize=3)\n",
    "moving_average.plot(label='5-Month Moving Average', color='red')\n",
    "\n",
    "plt.title('Median Auction Discount and 5-Month Moving Average Over Time')\n",
    "plt.xlabel('')\n",
    "plt.legend(frameon=False)\n",
    "plt.grid(True, alpha=0.7, ls=':')\n",
    "#sns.despine()\n",
    "plt.box(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# x ticks in each year\n",
    "years = np.arange(0, len(median_group), 12) \n",
    "plt.gca().xaxis.set_major_locator(MultipleLocator(base=12)) \n",
    "plt.savefig('adi.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
